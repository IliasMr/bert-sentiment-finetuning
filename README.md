## About
This project is about developing a sentiment classifier by fine-tuning two HuggingFace models:
- the pretrained model **BERT**
- the pretrained model **DistilBERT**

This was a university project for the course: **Artificial Intelligence II - Deep Learning for NLP**.

## Dataset
The dataset that was used for this project is the english language Twitter dataset and can be found in the dataset folder.


## Used Libraries
- Pandas
- Numpy
- Scikit-learn
- Matplotlib
- Seaborn
- NLTK
- WordCloud
- PyTorch
- Transformers (Hugging Face)

## Results

Summary of the performance metrics for the final models:



| Metric | BERT  | DistilBERT |
| ------ | ---------- | ---------------- |
| Accuracy | 0.8530 | 0.8485 |
| Precision | 0.8530 | 0.8486 |
| Recall | 0.8530 | 0.8485 |
| F1 Score | 0.8530 | 0.8485 |



A comprehensive analysis of the models' performance, including results, metrics and relevant comments, is available on the report.pdf.

